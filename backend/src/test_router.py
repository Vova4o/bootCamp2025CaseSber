import asyncio
import sys
sys.path.append("src")

from agents.router_agent import RouterAgent
from tools.llm_factory import create_llm_client
from core.config import settings

async def test_router():
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    llm_client = create_llm_client(
        provider=settings.llm_provider,
        api_key=settings.openai_api_key if settings.llm_provider == "openai" else settings.llm_api_key,
        base_url=settings.llm_api_url if settings.llm_provider == "local" else None,
        model=settings.openai_model if settings.llm_provider == "openai" else None
    )
    
    router = RouterAgent(llm_client)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        # Simple
        ("What is Python?", False),
        ("–ö–æ–≥–¥–∞ –æ—Å–Ω–æ–≤–∞–Ω Google?", False),
        ("–ö—Ç–æ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê?", False),
        
        # Pro
        ("–°—Ä–∞–≤–Ω–∏ Python –∏ Java –¥–ª—è –≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏", False),
        ("–ü–æ—á–µ–º—É –±–∏—Ç–∫–æ–∏–Ω —Ä–∞—Å—Ç–µ—Ç –≤ —Ü–µ–Ω–µ?", False),
        ("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–ª—é—Å—ã –∏ –º–∏–Ω—É—Å—ã —É–¥–∞–ª–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã", False),
        
        # –° –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        ("–†–∞—Å—Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ", True),
        ("–ê —á—Ç–æ –Ω–∞—Å—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏?", True),
    ]
    
    print("=" * 80)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï ROUTER AGENT")
    print("=" * 80)
    
    for query, has_context in test_queries:
        print(f"\nüìù –ó–∞–ø—Ä–æ—Å: '{query}'")
        print(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç: {'–µ—Å—Ç—å' if has_context else '–Ω–µ—Ç'}")
        
        # –¢–æ–ª—å–∫–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
        result_heuristic = await router.route(query, use_llm=False, context_exists=has_context)
        print(f"   üîß –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: {result_heuristic['mode'].upper()} "
              f"({result_heuristic['confidence']:.0%}) - {result_heuristic['reason']}")
        
        # –° LLM
        if settings.use_llm_router:
            result_llm = await router.route(query, use_llm=True, context_exists=has_context)
            print(f"   ü§ñ LLM:       {result_llm['mode'].upper()} "
                  f"({result_llm['confidence']:.0%}) - {result_llm['reason']}")
    
    await llm_client.close()
    print("\n" + "=" * 80)
    print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

if __name__ == "__main__":
    asyncio.run(test_router())