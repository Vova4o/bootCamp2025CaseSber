from typing import Dict, Literal
import logging
import re

logger = logging.getLogger(__name__)

class RouterAgent:
    """
    –ê–≥–µ–Ω—Ç-–º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞
    –∏ –≤—ã–±–æ—Ä–∞ –º–µ–∂–¥—É Simple –∏ Pro —Ä–µ–∂–∏–º–∞–º–∏
    """
    
    def __init__(self, llm_client):
        self.llm_client = llm_client
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
        self.pro_keywords = [
            # –°—Ä–∞–≤–Ω–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑
            "—Å—Ä–∞–≤–Ω–∏", "—Å—Ä–∞–≤–Ω–∏—Ç—å", "compare", "–æ—Ç–ª–∏—á–∏–µ", "difference", "versus", "vs",
            "–ª—É—á—à–µ", "—Ö—É–∂–µ", "better", "worse",
            
            # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã
            "–ø–ª—é—Å—ã –∏ –º–∏–Ω—É—Å—ã", "–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏", "pros and cons",
            "advantages", "disadvantages",
            
            # –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑
            "–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π", "analyze", "–∏—Å—Å–ª–µ–¥—É–π", "research",
            "–ø–æ–¥—Ä–æ–±–Ω–æ", "–¥–µ—Ç–∞–ª—å–Ω–æ", "detailed", "comprehensive",
            "–ø–æ—á–µ–º—É", "why", "–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç", "how does", "how works",
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–∫—Ç–æ–≤
            "–ø—Ä–∞–≤–¥–∞ –ª–∏", "is it true", "—Ñ–∞–∫—Ç", "fact check",
            "–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ", "reliable", "–ø—Ä–æ–≤–µ—Ä—å", "verify",
            
            # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            "–ø–æ –¥–∞–Ω–Ω—ã–º", "according to", "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç",
            "—ç–∫—Å–ø–µ—Ä—Ç—ã", "experts", "–º–Ω–µ–Ω–∏—è", "opinions",
            
            # –°–ª–æ–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
            "–æ–±—ä—è—Å–Ω–∏", "explain", "—Ä–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–æ", "tell me more",
            "–∫–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º", "how exactly", "–≤ —á–µ–º –ø—Ä–∏—á–∏–Ω–∞", "what causes",
        ]
        
        self.simple_keywords = [
            # –ü—Ä–æ—Å—Ç—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            "—á—Ç–æ —Ç–∞–∫–æ–µ", "what is", "–∫—Ç–æ —Ç–∞–∫–æ–π", "who is",
            "–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "definition", "–∑–Ω–∞—á–µ–Ω–∏–µ", "meaning",
            
            # –ü—Ä–æ—Å—Ç—ã–µ —Ñ–∞–∫—Ç—ã
            "–∫–æ–≥–¥–∞", "when", "–≥–¥–µ", "where", "—Å–∫–æ–ª—å–∫–æ", "how many", "how much",
            "–¥–∞—Ç–∞", "date", "–≥–æ–¥", "year",
            
            # –ü—Ä–æ—Å—Ç—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
            "–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å", "how to", "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "instruction",
        ]
    
    async def route(
        self, 
        query: str, 
        use_llm: bool = True,
        context_exists: bool = False
    ) -> Dict[Literal["mode", "confidence", "reason"], any]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            use_llm: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ LLM –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            context_exists: –ï—Å—Ç—å –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
        
        Returns:
            {
                "mode": "simple" | "pro",
                "confidence": float (0-1),
                "reason": str
            }
        """
        # –®–∞–≥ 1: –ë—ã—Å—Ç—Ä–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
        heuristic_result = self._heuristic_check(query, context_exists)
        
        # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è (>0.8), –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
        if heuristic_result["confidence"] > 0.8 or not use_llm:
            logger.info(
                f"Router decision (heuristic): {heuristic_result['mode']} "
                f"(confidence: {heuristic_result['confidence']:.2f}) - {heuristic_result['reason']}"
            )
            return heuristic_result
        
        # –®–∞–≥ 2: LLM –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        try:
            llm_result = await self._llm_classify(query, context_exists)
            logger.info(
                f"Router decision (LLM): {llm_result['mode']} "
                f"(confidence: {llm_result['confidence']:.2f}) - {llm_result['reason']}"
            )
            return llm_result
        except Exception as e:
            logger.error(f"LLM classification failed: {e}, using heuristic")
            return heuristic_result
    
    def _heuristic_check(self, query: str, context_exists: bool) -> Dict:
        """–ë—ã—Å—Ç—Ä–∞—è —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞"""
        query_lower = query.lower()
        words = query.split()
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 1: –î–ª–∏–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞
        if len(words) <= 4:
            return {
                "mode": "simple",
                "confidence": 0.9,
                "reason": "–ö–æ—Ä–æ—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å (‚â§4 —Å–ª–æ–≤)"
            }
        
        if len(words) >= 15:
            return {
                "mode": "pro",
                "confidence": 0.85,
                "reason": "–î–ª–∏–Ω–Ω—ã–π —Å–ª–æ–∂–Ω—ã–π –∑–∞–ø—Ä–æ—Å (‚â•15 —Å–ª–æ–≤)"
            }
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 2: –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if context_exists:
            return {
                "mode": "pro",
                "confidence": 0.8,
                "reason": "–ï—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º Pro –¥–ª—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏"
            }
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 3: –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ Pro —Ä–µ–∂–∏–º–∞
        pro_matches = sum(1 for keyword in self.pro_keywords if keyword in query_lower)
        if pro_matches >= 2:
            return {
                "mode": "pro",
                "confidence": 0.9,
                "reason": f"–ù–∞–π–¥–µ–Ω–æ {pro_matches} –º–∞—Ä–∫–µ—Ä–æ–≤ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"
            }
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 4: –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ Simple —Ä–µ–∂–∏–º–∞
        simple_matches = sum(1 for keyword in self.simple_keywords if keyword in query_lower)
        if simple_matches >= 1:
            return {
                "mode": "simple",
                "confidence": 0.85,
                "reason": f"–ù–∞–π–¥–µ–Ω–æ {simple_matches} –º–∞—Ä–∫–µ—Ä–æ–≤ –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"
            }
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 5: –í–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        question_words = ["–∫–∞–∫", "—á—Ç–æ", "–≥–¥–µ", "–∫–æ–≥–¥–∞", "–ø–æ—á–µ–º—É", "–∑–∞—á–µ–º", 
                         "how", "what", "where", "when", "why"]
        if any(query_lower.startswith(q) for q in question_words):
            # "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç" - pro, "–ö–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è" - simple
            if any(word in query_lower for word in ["—Ä–∞–±–æ—Ç–∞–µ—Ç", "—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É–µ—Ç", "—É—Å—Ç—Ä–æ–µ–Ω", "works", "functions"]):
                return {
                    "mode": "pro",
                    "confidence": 0.75,
                    "reason": "–í–æ–ø—Ä–æ—Å –æ –º–µ—Ö–∞–Ω–∏–∑–º–µ —Ä–∞–±–æ—Ç—ã"
                }
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 6: –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        if query.count("?") > 1 or query.count(" –∏ ") > 2:
            return {
                "mode": "pro",
                "confidence": 0.8,
                "reason": "–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –∞—Å–ø–µ–∫—Ç—ã"
            }
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 7: –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - —Å—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        if len(words) <= 8:
            return {
                "mode": "simple",
                "confidence": 0.6,
                "reason": "–°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å, —Å–∫–ª–æ–Ω—è–µ–º—Å—è –∫ Simple –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏"
            }
        else:
            return {
                "mode": "pro",
                "confidence": 0.6,
                "reason": "–°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å, —Å–∫–ª–æ–Ω—è–µ–º—Å—è –∫ Pro –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞"
            }
    
    async def _llm_classify(self, query: str, context_exists: bool) -> Dict:
        """LLM –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤"""
        
        system_prompt = """–¢—ã - –∞–≥–µ–Ω—Ç-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–æ–≤. –û–ø—Ä–µ–¥–µ–ª–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –≤–æ–ø—Ä–æ—Å–∞.

SIMPLE MODE (‚ö° –±—ã—Å—Ç—Ä—ã–π):
- –ü—Ä–æ—Å—Ç—ã–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏ –∑–Ω–∞—á–µ–Ω–∏—è
- –î–∞—Ç—ã, —á–∏—Å–ª–∞, –ø—Ä–æ—Å—Ç—ã–µ —Ñ–∞–∫—Ç—ã
- –ö–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã –∏–∑ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
–ü—Ä–∏–º–µ—Ä—ã: "–ß—Ç–æ —Ç–∞–∫–æ–µ Python?", "–ö–æ–≥–¥–∞ –æ—Å–Ω–æ–≤–∞–Ω Google?", "–ö—Ç–æ –∞–≤—Ç–æ—Ä –∫–Ω–∏–≥–∏ X?"

PRO MODE (üß† –≥–ª—É–±–æ–∫–∏–π):
- –°—Ä–∞–≤–Ω–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–∫—Ç–æ–≤
- –í–æ–ø—Ä–æ—Å—ã —Ç—Ä–µ–±—É—é—â–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
- –°–ª–æ–∂–Ω—ã–µ "–ø–æ—á–µ–º—É" –∏ "–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç"
–ü—Ä–∏–º–µ—Ä—ã: "–°—Ä–∞–≤–Ω–∏ Python –∏ Java", "–ü–æ—á–µ–º—É Bitcoin —Ä–∞—Å—Ç–µ—Ç?", "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç—å?"

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ: MODE|CONFIDENCE|REASON
–ì–¥–µ MODE = simple –∏–ª–∏ pro, CONFIDENCE = 0.0-1.0, REASON = –∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ

–ü—Ä–∏–º–µ—Ä: pro|0.85|–¢—Ä–µ–±—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""

        user_prompt = f"""–ó–∞–ø—Ä–æ—Å: "{query}"
–ï—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞: {"–¥–∞" if context_exists else "–Ω–µ—Ç"}

–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å:"""

        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            response = await self.llm_client.chat_completion(
                messages=messages,
                temperature=0.3,
                max_tokens=100
            )
            
            # –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
            parts = response.strip().split("|")
            if len(parts) >= 3:
                mode = parts[0].strip().lower()
                confidence = float(parts[1].strip())
                reason = parts[2].strip()
                
                if mode not in ["simple", "pro"]:
                    mode = "simple"
                
                confidence = max(0.0, min(1.0, confidence))
                
                return {
                    "mode": mode,
                    "confidence": confidence,
                    "reason": f"LLM: {reason}"
                }
            else:
                raise ValueError("Invalid response format")
                
        except Exception as e:
            logger.error(f"LLM parsing error: {e}, response: {response if 'response' in locals() else 'N/A'}")
            # Fallback –∫ —ç–≤—Ä–∏—Å—Ç–∏–∫–µ
            return self._heuristic_check(query, context_exists)