from typing import Dict, List
import logging
import time

logger = logging.getLogger(__name__)


async def process_pro_mode_with_context(
    query: str,
    search_client,
    llm_client,
    conversation_history: List[Dict] = None,
    max_results: int = 10
) -> Dict:
    """
    Pro Mode —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.
    
    Args:
        query: –¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å
        search_client: –ö–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
        llm_client: –ö–ª–∏–µ–Ω—Ç LLM
        conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ [{"role": "user/assistant", "content": "..."}]
        max_results: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
    """
    start_time = time.time()
    reasoning_steps = []
    
    try:
        # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        if conversation_history and len(conversation_history) > 0:
            reasoning_steps.append("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞...")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
            context_prompt = "–ü—Ä–µ–¥—ã–¥—É—â–∞—è –±–µ—Å–µ–¥–∞:\n"
            for msg in conversation_history[-6:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
                role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg["role"] == "user" else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                context_prompt += f"\n{role}: {msg['content']}\n"
            
            # –£–ª—É—á—à–∞–µ–º –∑–∞–ø—Ä–æ—Å —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            enhanced_query = await llm_client.chat_completion(
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞. –ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω –±—ã–ª —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∏ –≤–∫–ª—é—á–∞–ª –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
                    },
                    {
                        "role": "user",
                        "content": f"{context_prompt}\n\n–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å: {query}\n\n–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å:"
                    }
                ],
                temperature=0.3,
                max_tokens=200
            )
            
            reasoning_steps.append(f"‚ú® –£–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {enhanced_query}")
            search_query = enhanced_query
        else:
            search_query = query
            reasoning_steps.append("üìù –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –ø–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
        
        # –®–∞–≥ 2: –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        reasoning_steps.append(f"üîé –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∑–∞–ø—Ä–æ—Å—É: {search_query}")
        search_results = await search_client.search(
            query=search_query,
            max_results=max_results,
            include_raw_content=True
        )
        
        if not search_results.get("results"):
            return {
                "query": query,
                "mode": "pro",
                "answer": "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.",
                "sources": [],
                "reasoning": "\n".join(reasoning_steps),
                "processing_time": time.time() - start_time,
                "timestamp": time.time(),
                "context_used": len(conversation_history) > 0 if conversation_history else False
            }
        
        reasoning_steps.append(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(search_results['results'])} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
        
        # –®–∞–≥ 3: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        sources_context = "\n\n".join([
            f"–ò—Å—Ç–æ—á–Ω–∏–∫ {i+1} ({r.get('title', 'Unknown')}):\n{r.get('content', r.get('snippet', ''))}"
            for i, r in enumerate(search_results["results"][:5])
        ])
        
        # –°–æ–±–∏—Ä–∞–µ–º messages –¥–ª—è LLM
        llm_messages = [
            {
                "role": "system",
                "content": """–¢—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤ —Ä–µ–∂–∏–º–µ Pro. 
                –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –¥–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π, —Ö–æ—Ä–æ—à–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —É—á—ë—Ç–æ–º:
                1. –ö–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –±–µ—Å–µ–¥—ã
                2. –ù–∞–π–¥–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                3. –ü—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–∫—Ç–æ–≤
                
                –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
                - –ü—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å
                - –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —Ñ–∞–∫—Ç–∞–º–∏ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                - –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                - –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤–∞ - —É–∫–∞–∂–∏ —ç—Ç–æ"""
            }
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
        if conversation_history:
            for msg in conversation_history[-4:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 2 –ø–∞—Ä—ã
                llm_messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        llm_messages.append({
            "role": "user",
            "content": f"–í–æ–ø—Ä–æ—Å: {query}\n\n–ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n{sources_context}\n\n–û—Ç–≤–µ—Ç:"
        })
        
        reasoning_steps.append("üí° –§–æ—Ä–º–∏—Ä—É—é –æ—Ç–≤–µ—Ç —Å —É—á—ë—Ç–æ–º –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        answer = await llm_client.chat_completion(
            messages=llm_messages,
            temperature=0.7,
            max_tokens=1000
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        formatted_sources = [
            {
                "title": r.get("title", "Unknown"),
                "url": r.get("url", "#"),
                "snippet": r.get("snippet", "")[:200],
                "credibility": 0.85  # TODO: —Ä–µ–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏
            }
            for r in search_results["results"][:5]
        ]
        
        return {
            "query": query,
            "mode": "pro",
            "answer": answer,
            "sources": formatted_sources,
            "reasoning": "\n".join(reasoning_steps),
            "processing_time": time.time() - start_time,
            "timestamp": time.time(),
            "context_used": len(conversation_history) > 0 if conversation_history else False
        }
        
    except Exception as e:
        logger.error(f"Pro mode with context error: {e}")
        return {
            "query": query,
            "mode": "pro",
            "answer": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}",
            "sources": [],
            "reasoning": "\n".join(reasoning_steps + [f"‚ùå –û—à–∏–±–∫–∞: {str(e)}"]),
            "processing_time": time.time() - start_time,
            "timestamp": time.time(),
            "context_used": False
        }