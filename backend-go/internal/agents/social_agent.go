package agents

import (
	"context"
	"fmt"
	"log"
	"strings"

	"github.com/Vova4o/bootCamp2025CaseSber/backend/internal/models"
	"github.com/Vova4o/bootCamp2025CaseSber/backend/internal/scrapers"
	"github.com/Vova4o/bootCamp2025CaseSber/backend/internal/tools"
)

type SocialAgent struct {
	socialScraper *scrapers.SocialScraper
	llmClient     *tools.LLMClient
	reranker      *tools.BM25Reranker
}

func NewSocialAgent(llmClient *tools.LLMClient) *SocialAgent {
	return &SocialAgent{
		socialScraper: scrapers.NewSocialScraper(),
		llmClient:     llmClient,
		reranker:      tools.NewBM25Reranker(),
	}
}

func (a *SocialAgent) Process(ctx context.Context, query string) (*models.SearchResponse, error) {
	return a.ProcessWithContext(ctx, query, nil)
}

func (a *SocialAgent) ProcessWithContext(
	ctx context.Context,
	query string,
	conversationHistory []models.Message,
) (*models.SearchResponse, error) {
	log.Printf("Pro Social mode processing: %s", query)

	reasoningSteps := []string{"ğŸ—£ï¸ Ğ—Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ Ñ€ĞµĞ¶Ğ¸Ğ¼ Social - Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¼Ğ½ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ´Ğ¸ÑĞºÑƒÑÑĞ¸Ğ¹"}

	searchQuery := query
	if len(conversationHistory) > 0 {
		reasoningSteps = append(reasoningSteps, "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€ÑƒÑ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°...")
		enhanced, err := a.enhanceQueryWithContext(ctx, query, conversationHistory)
		if err == nil && enhanced != "" {
			searchQuery = enhanced
		}
	}

	// ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ² ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞµÑ‚ÑÑ…
	reasoningSteps = append(reasoningSteps, "Ğ˜Ñ‰Ñƒ Ğ¼Ğ½ĞµĞ½Ğ¸Ñ Ğ² Reddit, Habr, Twitter...")

	allResults := make([]models.TavilyResult, 0)

	// Reddit
	redditResults, err := a.socialScraper.SearchReddit(ctx, searchQuery, 5)
	if err != nil {
		log.Printf("Reddit search failed: %v", err)
	} else {
		allResults = append(allResults, redditResults...)
		reasoningSteps = append(reasoningSteps, fmt.Sprintf("âœ“ Reddit: %d Ğ¾Ğ±ÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹", len(redditResults)))
	}

	// Habr
	habrResults, err := a.socialScraper.SearchHabr(ctx, searchQuery, 5)
	if err != nil {
		log.Printf("Habr search failed: %v", err)
	} else {
		allResults = append(allResults, habrResults...)
		reasoningSteps = append(reasoningSteps, fmt.Sprintf("âœ“ Habr: %d ÑÑ‚Ğ°Ñ‚ĞµĞ¹", len(habrResults)))
	}

	// Twitter
	twitterResults, err := a.socialScraper.SearchTwitter(ctx, searchQuery, 5)
	if err != nil {
		log.Printf("Twitter search failed: %v", err)
	} else {
		allResults = append(allResults, twitterResults...)
		reasoningSteps = append(reasoningSteps, fmt.Sprintf("âœ“ Twitter: %d Ñ‚Ğ²Ğ¸Ñ‚Ğ¾Ğ²", len(twitterResults)))
	}

	if len(allResults) == 0 {
		return &models.SearchResponse{
			Query:     query,
			Mode:      "pro-social",
			Answer:    "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ¾Ğ±ÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ²Ğ°ÑˆĞµĞ¼Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ Ğ² ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞµÑ‚ÑÑ….",
			Sources:   []models.Source{},
			Reasoning: strings.Join(reasoningSteps, "\n"),
		}, nil
	}

	reasoningSteps = append(reasoningSteps, fmt.Sprintf("Ğ¡Ğ¾Ğ±Ñ€Ğ°Ğ½Ğ¾ %d Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ², Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑ reranking...", len(allResults)))

	// Rerank
	allResults = a.reranker.Rerank(searchQuery, allResults)

	// Take top 10
	if len(allResults) > 10 {
		allResults = allResults[:10]
	}

	// Analyze sentiment
	reasoningSteps = append(reasoningSteps, "ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¾Ğ±Ñ‰ĞµĞµ Ğ¼Ğ½ĞµĞ½Ğ¸Ğµ...")

	// Build LLM prompt
	var promptBuilder strings.Builder
	promptBuilder.WriteString(`Ğ¢Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼ĞµĞ´Ğ¸Ğ°. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ¼Ğ½ĞµĞ½Ğ¸Ñ Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ².

Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°:
1. ĞĞ±Ğ¾Ğ±Ñ‰Ğ¸Ñ‚ÑŒ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ½ĞµĞ½Ğ¸Ñ Ğ¸ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ·Ñ€ĞµĞ½Ğ¸Ñ
2. Ğ’Ñ‹ÑĞ²Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸Ñ
3. Ğ£ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ (Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ/Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ/Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ğ°Ñ)
4. ĞÑ‚Ğ¼ĞµÑ‚Ğ¸Ñ‚ÑŒ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ğµ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹

`)

	if len(conversationHistory) > 0 {
		promptBuilder.WriteString("\nĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°:\n")
		for _, msg := range conversationHistory[max(0, len(conversationHistory)-4):] {
			promptBuilder.WriteString(fmt.Sprintf("%s: %s\n", msg.Role, msg.Content))
		}
		promptBuilder.WriteString("\n")
	}

	promptBuilder.WriteString(fmt.Sprintf("Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: %s\n\n", query))
	promptBuilder.WriteString("ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ½ĞµĞ½Ğ¸Ñ:\n\n")

	for i, result := range allResults {
		if i >= 8 {
			break
		}
		content := result.Content
		if len(content) > 500 {
			content = content[:500]
		}
		promptBuilder.WriteString(fmt.Sprintf("Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº %d (%s):\n%s\n\n", i+1, result.Title, content))
	}

	promptBuilder.WriteString("\nĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¼Ğ½ĞµĞ½Ğ¸Ğ¹:")

	reasoningSteps = append(reasoningSteps, "Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒÑ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·...")

	answer, err := a.llmClient.Complete(ctx, promptBuilder.String(), 0.7, 1000)
	if err != nil {
		return nil, fmt.Errorf("LLM completion failed: %w", err)
	}

	// Format sources
	sources := make([]models.Source, 0)
	for i, result := range allResults {
		if i >= 8 {
			break
		}
		snippet := result.Content
		if len(snippet) > 200 {
			snippet = snippet[:200] + "..."
		}
		sources = append(sources, models.Source{
			Title:       result.Title,
			URL:         result.URL,
			Snippet:     snippet,
			Credibility: result.Score,
		})
	}

	return &models.SearchResponse{
		Query:       query,
		Mode:        "pro-social",
		Answer:      answer,
		Sources:     sources,
		Reasoning:   strings.Join(reasoningSteps, "\n"),
		ContextUsed: len(conversationHistory) > 0,
	}, nil
}

func (a *SocialAgent) enhanceQueryWithContext(
	ctx context.Context,
	query string,
	conversationHistory []models.Message,
) (string, error) {
	var contextPrompt strings.Builder
	contextPrompt.WriteString("ĞŸÑ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ°Ñ Ğ±ĞµÑĞµĞ´Ğ°:\n")
	for _, msg := range conversationHistory[max(0, len(conversationHistory)-4):] {
		role := "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ"
		if msg.Role == "assistant" {
			role = "ĞÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚"
		}
		contextPrompt.WriteString(fmt.Sprintf("%s: %s\n", role, msg.Content))
	}

	enhancePrompt := fmt.Sprintf(`%s

Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ: %s

ĞŸĞµÑ€ĞµÑ„Ñ€Ğ°Ğ·Ğ¸Ñ€ÑƒĞ¹ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ñ‚Ğ°Ğº, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¾Ğ½ Ğ±Ñ‹Ğ» ÑĞ°Ğ¼Ğ¾Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¼ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞµÑ‚ÑÑ…. Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ:`, contextPrompt.String(), query)

	return a.llmClient.Complete(ctx, enhancePrompt, 0.3, 150)
}

func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}